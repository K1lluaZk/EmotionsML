<p align="center">EmotionsML - Core Engine</p>
<p align="center">El nÃºcleo de procesamiento de IA que gestiona la captura de video y la inferencia de emociones en tiempo real.</p>

<p align="center"> <img src="https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white" alt="Python"> <img src="https://img.shields.io/badge/OpenCV-5C3EE8?style=flat&logo=opencv&logoColor=white" alt="OpenCV"> <img src="https://img.shields.io/badge/DeepFace-E34F26?style=flat&logo=scikitlearn&logoColor=white" alt="DeepFace"> </p>

---

### ğŸ§  Sobre el MÃ³dulo Src

Esta carpeta contiene la **LÃ³gica de Negocio** y el **Motor de Inferencia**. Es el corazÃ³n del proyecto, donde se transforma el flujo de datos de la cÃ¡mara en informaciÃ³n analÃ­tica sobre el estado emocional del usuario. Se ha diseÃ±ado bajo un esquema de desacoplamiento para permitir que el modelo de detecciÃ³n sea independiente de la interfaz de visualizaciÃ³n.

### âœ¨ CaracterÃ­sticas del Motor (`main.py`)

* **ğŸ® OrquestaciÃ³n en Tiempo Real:** El script `main.py` actÃºa como el controlador principal, gestionando el ciclo de vida de la cÃ¡mara (`VideoCapture`) y la liberaciÃ³n de recursos del sistema.
* **âš¡ OptimizaciÃ³n de Inferencia:** Implementa un sistema de **conteo de frames** para ejecutar la IA de forma intermitente, evitando el desfase (lag) entre la captura y el procesamiento.
* **ğŸ–¼ï¸ SuperposiciÃ³n de UI (HUD):** Renderiza dinÃ¡micamente etiquetas de texto sobre el video utilizando las funciones de dibujo de OpenCV, mostrando la emociÃ³n detectada sin interrumpir el flujo visual.
* **âš™ï¸ ConfiguraciÃ³n Centralizada:** Utiliza `config.py` para abstraer constantes como el `FRAME_SKIP`, escalas de fuente y colores, permitiendo ajustes rÃ¡pidos sin tocar la lÃ³gica principal.
* **ğŸ›¡ï¸ Estabilidad del Proceso:** Incluye bloques `try-except` para manejar excepciones durante el anÃ¡lisis de DeepFace, garantizando que el programa no se cierre si la detecciÃ³n falla momentÃ¡neamente.

### ğŸ› ï¸ Componentes Internos

* **`main.py`**: Punto de entrada del programa. Contiene el bucle principal de video y la lÃ³gica de visualizaciÃ³n.
* **`detectemotions.py`**: Clase `EmotionDetector` que encapsula la librerÃ­a **DeepFace**. Su Ãºnico objetivo es procesar un frame y retornar el nombre de la emociÃ³n.
* **`config.py`**: Diccionario de parÃ¡metros tÃ©cnicos para el ajuste fino del rendimiento.
* **`requirements.txt`**: Listado estricto de librerÃ­as necesarias para el funcionamiento del motor de IA.

### ğŸš€ CÃ³mo Ejecutar el Motor

1. **AsegÃºrate de estar en el entorno virtual:**
```bash
# Windows
venv\Scripts\activate

```


2. **Ejecuta el script principal:**
```bash
python Src/main.py

```


3. **Controles de Usuario:**
* **'q'**: Finaliza la ejecuciÃ³n y cierra las ventanas.
* **Cerrar ventana**: El programa detecta el cierre manual de la ventana y libera la cÃ¡mara automÃ¡ticamente.



### ğŸ“ Estructura del MÃ³dulo

```text
â”œâ”€â”€ config.py           # Variables de entorno y ajustes tÃ©cnicos
â”œâ”€â”€ detectemotions.py   # Wrapper del modelo de Machine Learning
â”œâ”€â”€ main.py             # Script principal (Orquestador)
â””â”€â”€ requirements.txt    # Dependencias especÃ­ficas de ML y VisiÃ³n

```

### âœï¸ Autor

**K1lluaZk** - [Perfil de GitHub](https://www.google.com/search?q=https://github.com/K1lluaZk)

### ğŸ“„ Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la **Licencia MIT**.

---

